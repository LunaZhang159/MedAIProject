{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078f799e",
   "metadata": {},
   "source": [
    "# ğŸ§  Rare Disease GraphRAG QA Pipeline\n",
    "åŸºäº `medical_doc1.pdf` æ„å»ºçŸ¥è¯†å›¾è°± + å›¾è°±å¢å¼ºé—®ç­”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5bc0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -U langchain openai faiss-cpu networkx matplotlib sentence-transformers pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2814952",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from difflib import get_close_matches\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72db885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'your-api-key'  # è¯·æ›¿æ¢ä¸ºä½ çš„ OpenAI API å¯†é’¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = PyPDFLoader(\"medical_doc1.pdf\")\n",
    "docs = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "print(f\"âœ… æ–‡æ¡£åŠ è½½å®Œæˆï¼Œåˆ†å—æ•°é‡ï¼š{len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2422507",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ast\n",
    "\n",
    "prompt = \"\"\"Extract all rare disease names mentioned in the following biomedical text.\n",
    "Return only a valid Python list of strings (e.g. [\"Fabry disease\", \"Fryns syndrome\"]).\n",
    "Do NOT include explanation, just the list.\n",
    "\n",
    "Text:\n",
    "\"\"\" + all_text\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "try:\n",
    "    rare_diseases = ast.literal_eval(response.strip())\n",
    "    print(f\"ğŸ§¬ å…±è¯†åˆ«å‡º {len(rare_diseases)} ç§ rare diseasesã€‚\\n\")\n",
    "    print(\"ğŸ“‹ ç¤ºä¾‹åç§°:\", rare_diseases[:10])\n",
    "except Exception as e:\n",
    "    print(\"âŒ è§£æå¤±è´¥ï¼š\", e)\n",
    "    print(\"âš ï¸ GPT è¿”å›å†…å®¹ï¼š\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize(text):\n",
    "    return re.sub(r\"\\(.*?\\)\", \"\", text.lower()).strip()\n",
    "\n",
    "def extract_triplets(text):\n",
    "    pattern = r\"\\(([^()]+?), ([^()]+?), ([^()]+?)\\)\"\n",
    "    return re.findall(pattern, text)\n",
    "\n",
    "G = nx.DiGraph()\n",
    "rare_disease_names = [\"Fabry disease\", \"Fryns syndrome\", \"Ataxia telangiectasia\", \"Gaucher disease\"]  # å¯æ›¿æ¢ä¸ºå®é™…æå–\n",
    "for chunk in chunks:\n",
    "    prompt = f\"\"\"Extract factual triples (head, relation, tail) from this medical text:\\n\\n{chunk.page_content}\\n\\nReturn only (head, relation, tail).\"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "        for h, r, t in extract_triplets(result):\n",
    "        if not any(rd.lower() in h.lower() for rd in rare_disease_names):\n",
    "            continue  # åªä¿ç•™ head æ˜¯ rare disease çš„ä¸‰å…ƒç»„\n",
    "        G.add_node(normalize(h))\n",
    "        G.add_node(normalize(t))\n",
    "        G.add_edge(normalize(h), normalize(t), relation=r.strip())\n",
    "\n",
    "print(f\"âœ… çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆï¼ŒåŒ…å« {len(G.nodes)} ä¸ªèŠ‚ç‚¹ï¼Œ{len(G.edges)} æ¡è¾¹ã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3793f501",
   "metadata": {},
   "source": [
    "### ğŸ“‹ å›¾è°±ä¸­çš„ä¸‰å…ƒç»„ (head, relation, tail) ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b8c34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "triples = [(u, d.get(\"relation\", \"\"), v) for u, v, d in G.edges(data=True)]\n",
    "print(f\"å…±æå– {len(triples)} æ¡ä¸‰å…ƒç»„ã€‚\\n\")\n",
    "for t in triples[:10]:\n",
    "    print(\"ğŸ§ \", t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "nx.draw(G, pos, with_labels=True, node_color=\"skyblue\", edge_color=\"gray\", node_size=1000, font_size=8)\n",
    "edge_labels = nx.get_edge_attributes(G, \"relation\")\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)\n",
    "plt.title(\"Rare Disease Knowledge Graph\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e1ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectordb = FAISS.from_documents(chunks, embedding_model)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectordb.as_retriever(), return_source_documents=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def graphrag_query(question):\n",
    "    ent_prompt = f\"\"\"Extract the rare disease or symptom entities from this question.\\nReturn as a Python list:\\n\\n{question}\"\"\"\n",
    "    response = llm.invoke(ent_prompt)\n",
    "    try:\n",
    "        extracted = eval(response.strip())\n",
    "    except:\n",
    "        extracted = []\n",
    "\n",
    "    hits = []\n",
    "    for e in extracted:\n",
    "        match = get_close_matches(normalize(e), G.nodes, n=1, cutoff=0.5)\n",
    "        if match: hits.append(match[0])\n",
    "\n",
    "    if not hits:\n",
    "        print(\"âš ï¸ æœªåœ¨å›¾è°±ä¸­åŒ¹é…åˆ°å®ä½“ï¼Œæ”¹ä¸ºçº¯æ–‡æ¡£é—®ç­”\")\n",
    "        return qa_chain.invoke(question)[\"result\"]\n",
    "\n",
    "    neighbor_contexts = []\n",
    "    for node in hits:\n",
    "        neighbors = list(nx.single_source_shortest_path_length(G, node, cutoff=2))\n",
    "        neighbor_contexts.append(f\"Entity: {node}\\nNeighbors: {', '.join(neighbors)}\")\n",
    "\n",
    "    vector_docs = vectordb.similarity_search(question, k=2)\n",
    "    vector_text = \"\\n\".join(doc.page_content for doc in vector_docs)\n",
    "    graph_text = \"\\n\".join(neighbor_contexts)\n",
    "\n",
    "    final_prompt = f\"\"\"Answer based on graph and document knowledge:\\n\\nGraph:\\n{graph_text}\\n\\nDocs:\\n{vector_text}\\n\\nQuestion: {question}\"\"\"\n",
    "    return llm.invoke(final_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3949c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"What is Ataxia telangiectasia (AT)?\"\n",
    "print(\"ğŸ§  é—®é¢˜ï¼š\", query)\n",
    "print(\"ğŸ¤– å›ç­”ï¼š\", graphrag_query(query))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
