{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078f799e",
   "metadata": {},
   "source": [
    "# ğŸ§  Rare Disease GraphRAG QA Pipeline\n",
    "åŸºäº `medical_doc1.pdf` æ„å»ºçŸ¥è¯†å›¾è°± + å›¾è°±å¢å¼ºé—®ç­”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d538d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -U langchain openai faiss-cpu networkx matplotlib sentence-transformers pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from difflib import get_close_matches\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c324c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'your-api-key'  # è¯·æ›¿æ¢ä¸ºä½ çš„ OpenAI API å¯†é’¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b55ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = PyPDFLoader(\"medical_doc1.pdf\")\n",
    "docs = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "print(f\"âœ… æ–‡æ¡£åŠ è½½å®Œæˆï¼Œåˆ†å—æ•°é‡ï¼š{len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e32e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "all_text = \"\\n\".join([c.page_content for c in chunks[:15]])[:8000]\n",
    "prompt = \"\"\"Extract all rare disease names mentioned in the following biomedical text.\n",
    "Return only as a Python list of strings (no explanation).\n",
    "\n",
    "Text:\n",
    "\"\"\" + all_text\n",
    "response = llm.invoke(prompt)\n",
    "rare_diseases = eval(response)\n",
    "print(f\"ğŸ§¬ å…±è¯†åˆ«å‡º {len(rare_diseases)} ç§ rare diseasesã€‚\\n\")\n",
    "print(\"ğŸ“‹ ç¤ºä¾‹åç§°:\", rare_diseases[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize(text):\n",
    "    return re.sub(r\"\\(.*?\\)\", \"\", text.lower()).strip()\n",
    "\n",
    "def extract_triplets(text):\n",
    "    pattern = r\"\\(([^()]+?), ([^()]+?), ([^()]+?)\\)\"\n",
    "    return re.findall(pattern, text)\n",
    "\n",
    "G = nx.DiGraph()\n",
    "for chunk in chunks:\n",
    "    prompt = f\"\"\"Extract factual triples (head, relation, tail) from this medical text:\\n\\n{chunk.page_content}\\n\\nReturn only (head, relation, tail).\"\"\"\n",
    "    result = llm.invoke(prompt)\n",
    "    for h, r, t in extract_triplets(result):\n",
    "        G.add_node(normalize(h))\n",
    "        G.add_node(normalize(t))\n",
    "        G.add_edge(normalize(h), normalize(t), relation=r.strip())\n",
    "\n",
    "print(f\"âœ… çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆï¼ŒåŒ…å« {len(G.nodes)} ä¸ªèŠ‚ç‚¹ï¼Œ{len(G.edges)} æ¡è¾¹ã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394eb1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "nx.draw(G, pos, with_labels=True, node_color=\"skyblue\", edge_color=\"gray\", node_size=1000, font_size=8)\n",
    "edge_labels = nx.get_edge_attributes(G, \"relation\")\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)\n",
    "plt.title(\"Rare Disease Knowledge Graph\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6052232",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectordb = FAISS.from_documents(chunks, embedding_model)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectordb.as_retriever(), return_source_documents=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75030021",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def graphrag_query(question):\n",
    "    ent_prompt = f\"\"\"Extract the rare disease or symptom entities from this question.\\nReturn as a Python list:\\n\\n{question}\"\"\"\n",
    "    response = llm.invoke(ent_prompt)\n",
    "    try:\n",
    "        extracted = eval(response.strip())\n",
    "    except:\n",
    "        extracted = []\n",
    "\n",
    "    hits = []\n",
    "    for e in extracted:\n",
    "        match = get_close_matches(normalize(e), G.nodes, n=1, cutoff=0.5)\n",
    "        if match: hits.append(match[0])\n",
    "\n",
    "    if not hits:\n",
    "        print(\"âš ï¸ æœªåœ¨å›¾è°±ä¸­åŒ¹é…åˆ°å®ä½“ï¼Œæ”¹ä¸ºçº¯æ–‡æ¡£é—®ç­”\")\n",
    "        return qa_chain.invoke(question)[\"result\"]\n",
    "\n",
    "    neighbor_contexts = []\n",
    "    for node in hits:\n",
    "        neighbors = list(nx.single_source_shortest_path_length(G, node, cutoff=2))\n",
    "        neighbor_contexts.append(f\"Entity: {node}\\nNeighbors: {', '.join(neighbors)}\")\n",
    "\n",
    "    vector_docs = vectordb.similarity_search(question, k=2)\n",
    "    vector_text = \"\\n\".join(doc.page_content for doc in vector_docs)\n",
    "    graph_text = \"\\n\".join(neighbor_contexts)\n",
    "\n",
    "    final_prompt = f\"\"\"Answer based on graph and document knowledge:\\n\\nGraph:\\n{graph_text}\\n\\nDocs:\\n{vector_text}\\n\\nQuestion: {question}\"\"\"\n",
    "    return llm.invoke(final_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95965ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"What is Ataxia telangiectasia (AT)?\"\n",
    "print(\"ğŸ§  é—®é¢˜ï¼š\", query)\n",
    "print(\"ğŸ¤– å›ç­”ï¼š\", graphrag_query(query))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
